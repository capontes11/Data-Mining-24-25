{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please download:**\n",
    "\n",
    "- `figures/clustering/` folder\n",
    "- `data/data_preprocessed.csv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join('..', 'data', 'data_preprocessed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>frq</th>\n",
       "      <th>rcn</th>\n",
       "      <th>mnt</th>\n",
       "      <th>clothes</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>small_appliances</th>\n",
       "      <th>toys</th>\n",
       "      <th>house_keeping</th>\n",
       "      <th>...</th>\n",
       "      <th>oh_status_Widow</th>\n",
       "      <th>oh_gender_M</th>\n",
       "      <th>oh_dependents_1.0</th>\n",
       "      <th>oh_description_Kind of OK</th>\n",
       "      <th>oh_description_Meh...</th>\n",
       "      <th>oh_description_OK nice!</th>\n",
       "      <th>oh_description_Take my money!!</th>\n",
       "      <th>PC0</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>0.743162</td>\n",
       "      <td>1.191605</td>\n",
       "      <td>0.457819</td>\n",
       "      <td>1402</td>\n",
       "      <td>-0.617023</td>\n",
       "      <td>-0.243065</td>\n",
       "      <td>1.216847</td>\n",
       "      <td>0.495837</td>\n",
       "      <td>-0.499274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896356</td>\n",
       "      <td>-1.937697</td>\n",
       "      <td>1.120781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>1.559488</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-1.535723</td>\n",
       "      <td>1537</td>\n",
       "      <td>0.166160</td>\n",
       "      <td>-0.790228</td>\n",
       "      <td>0.740464</td>\n",
       "      <td>-0.374374</td>\n",
       "      <td>-0.631907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.981092</td>\n",
       "      <td>-1.421498</td>\n",
       "      <td>0.785625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>-1.548542</td>\n",
       "      <td>-0.823463</td>\n",
       "      <td>0.557496</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.834573</td>\n",
       "      <td>1.672006</td>\n",
       "      <td>-0.371096</td>\n",
       "      <td>-0.809480</td>\n",
       "      <td>2.286023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.813108</td>\n",
       "      <td>0.381440</td>\n",
       "      <td>-0.780867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.550447</td>\n",
       "      <td>-1.402820</td>\n",
       "      <td>888</td>\n",
       "      <td>0.383710</td>\n",
       "      <td>0.440889</td>\n",
       "      <td>-0.768082</td>\n",
       "      <td>-0.084304</td>\n",
       "      <td>-0.234007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.247013</td>\n",
       "      <td>-0.514177</td>\n",
       "      <td>-1.302203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>0.782435</td>\n",
       "      <td>1.008417</td>\n",
       "      <td>-0.871209</td>\n",
       "      <td>1138</td>\n",
       "      <td>0.340200</td>\n",
       "      <td>-0.243065</td>\n",
       "      <td>-0.053508</td>\n",
       "      <td>-0.374374</td>\n",
       "      <td>-0.366640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.781920</td>\n",
       "      <td>-0.704805</td>\n",
       "      <td>-0.443376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age    income       frq       rcn   mnt   clothes   kitchen  \\\n",
       "0   78  0.743162  1.191605  0.457819  1402 -0.617023 -0.243065   \n",
       "1   88  1.559488  1.100011 -1.535723  1537  0.166160 -0.790228   \n",
       "2   34 -1.548542 -0.823463  0.557496    44 -0.834573  1.672006   \n",
       "3   69  0.845528  0.550447 -1.402820   888  0.383710  0.440889   \n",
       "4   69  0.782435  1.008417 -0.871209  1138  0.340200 -0.243065   \n",
       "\n",
       "   small_appliances      toys  house_keeping  ...  oh_status_Widow  \\\n",
       "0          1.216847  0.495837      -0.499274  ...              0.0   \n",
       "1          0.740464 -0.374374      -0.631907  ...              0.0   \n",
       "2         -0.371096 -0.809480       2.286023  ...              0.0   \n",
       "3         -0.768082 -0.084304      -0.234007  ...              0.0   \n",
       "4         -0.053508 -0.374374      -0.366640  ...              0.0   \n",
       "\n",
       "   oh_gender_M oh_dependents_1.0 oh_description_Kind of OK  \\\n",
       "0          1.0               0.0                       0.0   \n",
       "1          0.0               0.0                       0.0   \n",
       "2          1.0               1.0                       1.0   \n",
       "3          0.0               1.0                       0.0   \n",
       "4          0.0               1.0                       0.0   \n",
       "\n",
       "  oh_description_Meh... oh_description_OK nice!  \\\n",
       "0                   0.0                     0.0   \n",
       "1                   0.0                     0.0   \n",
       "2                   0.0                     0.0   \n",
       "3                   0.0                     1.0   \n",
       "4                   0.0                     0.0   \n",
       "\n",
       "   oh_description_Take my money!!       PC0       PC1       PC2  \n",
       "0                             1.0  0.896356 -1.937697  1.120781  \n",
       "1                             1.0  1.981092 -1.421498  0.785625  \n",
       "2                             0.0 -2.813108  0.381440 -0.780867  \n",
       "3                             0.0  1.247013 -0.514177 -1.302203  \n",
       "4                             1.0  1.781920 -0.704805 -0.443376  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'income', 'frq', 'rcn', 'mnt', 'clothes', 'kitchen',\n",
       "       'small_appliances', 'toys', 'house_keeping', 'dependents',\n",
       "       'per_net_purchase', 'gender', 'education', 'status', 'description',\n",
       "       'birth_year', 'spent_online', 'oh_education_2nd Cycle',\n",
       "       'oh_education_Graduation', 'oh_education_Master', 'oh_education_PhD',\n",
       "       'oh_status_Married', 'oh_status_Single', 'oh_status_Together',\n",
       "       'oh_status_Widow', 'oh_gender_M', 'oh_dependents_1.0',\n",
       "       'oh_description_Kind of OK', 'oh_description_Meh...',\n",
       "       'oh_description_OK nice!', 'oh_description_Take my money!!', 'PC0',\n",
       "       'PC1', 'PC2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting feature names into groups\n",
    "# Remember which metric_features we decided to keep?\n",
    "metric_features = ['income',\n",
    " 'frq',\n",
    " 'rcn',\n",
    " 'clothes',\n",
    " 'kitchen',\n",
    " 'small_appliances',\n",
    " 'toys',\n",
    " 'house_keeping',\n",
    " 'per_net_purchase',\n",
    " 'spent_online']\n",
    "\n",
    "non_metric_features = df.columns[df.columns.str.startswith('oh_')].tolist() # CODE HERE\n",
    "pc_features = df.columns[df.columns.str.startswith('PC')].tolist()  # CODE HERE\n",
    "\n",
    "unused_features = [i for i in df.columns if i not in (metric_features+non_metric_features+pc_features) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_features: ['income', 'frq', 'rcn', 'clothes', 'kitchen', 'small_appliances', 'toys', 'house_keeping', 'per_net_purchase', 'spent_online']\n",
      "non_metric_features: ['oh_education_2nd Cycle', 'oh_education_Graduation', 'oh_education_Master', 'oh_education_PhD', 'oh_status_Married', 'oh_status_Single', 'oh_status_Together', 'oh_status_Widow', 'oh_gender_M', 'oh_dependents_1.0', 'oh_description_Kind of OK', 'oh_description_Meh...', 'oh_description_OK nice!', 'oh_description_Take my money!!']\n",
      "unused_features: ['age', 'mnt', 'dependents', 'gender', 'education', 'status', 'description', 'birth_year']\n",
      "pc_features: ['PC0', 'PC1', 'PC2']\n"
     ]
    }
   ],
   "source": [
    "print('metric_features:', metric_features)\n",
    "print('non_metric_features:', non_metric_features)\n",
    "print('unused_features:', unused_features)\n",
    "print('pc_features:', pc_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "What is hierarchical clustering? \n",
    "\n",
    "How does it work? \n",
    "\n",
    "How does it relate to the distance matrix we discussed at the beginning of the course? ;)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](../figures/clustering/hierarch.gif)\n",
    "\n",
    "(From https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The distance matrix\n",
    "![](../figures/clustering/hc_distance_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different types of linkage\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_linkage_comparison_001.png)\n",
    "\n",
    "### How are they computed?\n",
    "![](../figures/clustering/linkage_types.jpeg)\n",
    "\n",
    "**Ward linkage**: minimizes the sum of squared differences within all clusters. It is a variance-minimizing approach and in this sense is similar to the k-means objective function but tackled with an agglomerative hierarchical approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics:\n",
    "- *bottom up approach*: each observation starts in its own cluster, and clusters are successively merged together\n",
    "- *greedy/local algorithm*: at each iteration tries to minimize the distance of cluster merging\n",
    "- *no realocation*: after an observation is assigned to a cluster, it can no longer change\n",
    "- *deterministic*: you always get the same answer when you run it\n",
    "- *scalability*: can become *very slow* for a large number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to apply Hierarchical Clustering?\n",
    "**Note: Which types of variables should be used for clustering?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing HC\n",
    "hclust = AgglomerativeClustering(linkage='ward', metric='euclidean', n_clusters=5)\n",
    "hc_labels = hclust.fit_predict(df[metric_features])\n",
    "hc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>frq</th>\n",
       "      <th>rcn</th>\n",
       "      <th>clothes</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>small_appliances</th>\n",
       "      <th>toys</th>\n",
       "      <th>house_keeping</th>\n",
       "      <th>per_net_purchase</th>\n",
       "      <th>spent_online</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.127360</td>\n",
       "      <td>1.054164</td>\n",
       "      <td>-0.086791</td>\n",
       "      <td>-0.565696</td>\n",
       "      <td>0.231780</td>\n",
       "      <td>0.639929</td>\n",
       "      <td>0.310619</td>\n",
       "      <td>0.148892</td>\n",
       "      <td>-1.352162</td>\n",
       "      <td>0.235598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.816389</td>\n",
       "      <td>-0.843022</td>\n",
       "      <td>0.084738</td>\n",
       "      <td>-0.190329</td>\n",
       "      <td>-0.130035</td>\n",
       "      <td>0.479371</td>\n",
       "      <td>-0.044491</td>\n",
       "      <td>-0.051491</td>\n",
       "      <td>0.645503</td>\n",
       "      <td>-0.753319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583921</td>\n",
       "      <td>0.696600</td>\n",
       "      <td>0.028464</td>\n",
       "      <td>0.512591</td>\n",
       "      <td>-0.310472</td>\n",
       "      <td>-0.414163</td>\n",
       "      <td>-0.309056</td>\n",
       "      <td>-0.288473</td>\n",
       "      <td>-0.184634</td>\n",
       "      <td>1.123735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.286292</td>\n",
       "      <td>-0.877714</td>\n",
       "      <td>0.170377</td>\n",
       "      <td>-1.464165</td>\n",
       "      <td>1.742958</td>\n",
       "      <td>-0.037862</td>\n",
       "      <td>1.366213</td>\n",
       "      <td>1.588910</td>\n",
       "      <td>0.813227</td>\n",
       "      <td>-0.816724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.141469</td>\n",
       "      <td>-0.441731</td>\n",
       "      <td>-0.195457</td>\n",
       "      <td>1.235357</td>\n",
       "      <td>-0.700710</td>\n",
       "      <td>-1.054846</td>\n",
       "      <td>-0.723419</td>\n",
       "      <td>-0.668869</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>-0.230577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          income       frq       rcn   clothes   kitchen  small_appliances  \\\n",
       "labels                                                                       \n",
       "0       1.127360  1.054164 -0.086791 -0.565696  0.231780          0.639929   \n",
       "1      -0.816389 -0.843022  0.084738 -0.190329 -0.130035          0.479371   \n",
       "2       0.583921  0.696600  0.028464  0.512591 -0.310472         -0.414163   \n",
       "3      -1.286292 -0.877714  0.170377 -1.464165  1.742958         -0.037862   \n",
       "4      -0.141469 -0.441731 -0.195457  1.235357 -0.700710         -1.054846   \n",
       "\n",
       "            toys  house_keeping  per_net_purchase  spent_online  \n",
       "labels                                                           \n",
       "0       0.310619       0.148892         -1.352162      0.235598  \n",
       "1      -0.044491      -0.051491          0.645503     -0.753319  \n",
       "2      -0.309056      -0.288473         -0.184634      1.123735  \n",
       "3       1.366213       1.588910          0.813227     -0.816724  \n",
       "4      -0.723419      -0.668869          0.418864     -0.230577  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Characterizing the clusters\n",
    "\n",
    "labels_series = pd.Series(hc_labels, \n",
    "                          name='labels', \n",
    "                          index=df.index # WHY df.index ??\n",
    "                          ) \n",
    "\n",
    "df_concat = pd.concat(\n",
    "    [df, labels_series],\n",
    "    axis=1)\n",
    "\n",
    "df_concat[metric_features+['labels']].groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are we done?\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "### ... Not yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the linkage method to choose:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need to understand the following:**\n",
    "\n",
    "---\n",
    "\n",
    "$$SS_{t} = \\sum\\limits_{i = 1}^n {{{({x_i} - \\overline x )}^2}}$$\n",
    "\n",
    "$$SS_{w} = \\sum\\limits_{k = 1}^K {\\sum\\limits_{i = 1}^{{n_k}} {{{({x_i} - {{\\overline x }_k})}^2}} }$$\n",
    "\n",
    "$$SS_{b} = \\sum\\limits_{k = 1}^K {{n_k}{{({{\\overline x }_k} - \\overline x )}^2}}$$\n",
    "\n",
    "---\n",
    "\n",
    "$$SS_{t} = SS_{w} + SS_{b}$$\n",
    "\n",
    "---\n",
    "\n",
    "where \n",
    "\n",
    "$n$ is the total number of observations, \n",
    "\n",
    "$x_i$ is the vector of the $i^{th}$ observation, \n",
    "\n",
    "$\\overline x$ is the centroid of the data, \n",
    "\n",
    "$K$  is the number of clusters, \n",
    "\n",
    "$n_k$ is the number of observations in the $k^{th}$ cluster,\n",
    "\n",
    "and $\\overline x_k$ is the centroid of the $k^{th}$ cluster.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/clustering/ss_figure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "Calculate the `SS_` values using Pandas / NumPy:\n",
    "\n",
    "*Hint: Using numpy*\n",
    "\n",
    "$x_i$ : `X = data.values`\n",
    "\n",
    "$\\overline{x}$ : `X.mean()`\n",
    "\n",
    "$\\overline{x}_k$ : `X[hc_labels==k].mean()`\n",
    "\n",
    "$n_k$ : `X[hc_labels==k].shape[0]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUMPY solution:\n",
    "\n",
    "# x_i       : X = df.values     : data\n",
    "# x_bar     : X.mean(axis=0)    : centroid of data\n",
    "# x_k       : X[hc_labels==k]   : points of cluster k\n",
    "# x_bar_k   : X_k.mean(axis=0)  : centroid of cluster k\n",
    "# n_k       : X_k.shape[0]\n",
    "\n",
    "X = df[metric_features].values\n",
    "\n",
    "# Computing SST\n",
    "sst = np.sum(np.square(X - X.mean(axis=0)), axis=0)\n",
    "\n",
    "# Computing SSW\n",
    "ssw_iter = []                   # Outer summation\n",
    "for i in np.unique(hc_labels):  # Loop for inner summation\n",
    "    X_k = X[hc_labels == i]     # Data points belonging to cluster k\n",
    "    inner_sum = np.sum(np.square(X_k - X_k.mean(axis=0)), axis=0)\n",
    "    ssw_iter.append(inner_sum)  \n",
    "ssw = np.sum(ssw_iter, axis=0)  # Outer summation\n",
    "\n",
    "# Computing SSB\n",
    "ssb_iter = []\n",
    "for i in np.unique(hc_labels):  # Loop for summation\n",
    "    X_k = X[hc_labels == i]     # Data points belonging to cluster k\n",
    "    ssb_iter.append(X_k.shape[0] * np.square(X_k.mean(axis=0) - X.mean(axis=0)))\n",
    "\n",
    "ssb = np.sum(ssb_iter, axis=0)\n",
    "\n",
    "# Verifying the formula\n",
    "np.round(sst) == np.round((ssw + ssb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the `SS_` values using Pandas / NumPy:\n",
    "\n",
    "**Now do it using pandas**\n",
    "\n",
    "*Hint:*\n",
    "\n",
    "$x_i$ : `data`\n",
    "\n",
    "$\\overline{x}$ : `data.mean()`\n",
    "\n",
    "$\\overline{x}_k$ : `data.loc[data['labels']==k].mean()`\n",
    "\n",
    "$n_k$ : `data.loc[data['labels']==k].shape[0]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's wrap them into functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap them into functions\n",
    "\n",
    "def get_ss(df, feats):\n",
    "    \"\"\"\n",
    "    Calculate the sum of squares (SS) for the given DataFrame.\n",
    "\n",
    "    The sum of squares is computed as the sum of the variances of each column\n",
    "    multiplied by the number of non-NA/null observations minus one.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame for which the sum of squares is to be calculated.\n",
    "    feats (list of str): A list of feature column names to be used in the calculation.\n",
    "\n",
    "    Returns:\n",
    "    float: The sum of squares of the DataFrame.\n",
    "    \"\"\"\n",
    "    df_ = df[feats]\n",
    "    ss = np.sum(df_.var() * (df_.count() - 1))\n",
    "    \n",
    "    return ss \n",
    "\n",
    "\n",
    "def get_ssb(df, feats, label_col):\n",
    "    \"\"\"\n",
    "    Calculate the between-group sum of squares (SSB) for the given DataFrame.\n",
    "    The between-group sum of squares is computed as the sum of the squared differences\n",
    "    between the mean of each group and the overall mean, weighted by the number of observations\n",
    "    in each group.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame containing the data.\n",
    "    feats (list of str): A list of feature column names to be used in the calculation.\n",
    "    label_col (str): The name of the column in the DataFrame that contains the group labels.\n",
    "    \n",
    "    Returns\n",
    "    float: The between-group sum of squares of the DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    ssb_i = 0\n",
    "    for i in np.unique(df[label_col]):\n",
    "        df_ = df.loc[:, feats]\n",
    "        X_ = df_.values\n",
    "        X_k = df_.loc[df[label_col] == i].values\n",
    "        \n",
    "        ssb_i += (X_k.shape[0] * (np.square(X_k.mean(axis=0) - X_.mean(axis=0))) )\n",
    "\n",
    "    ssb = np.sum(ssb_i)\n",
    "    \n",
    "\n",
    "    return ssb\n",
    "\n",
    "\n",
    "def get_ssw(df, feats, label_col):\n",
    "    \"\"\"\n",
    "    Calculate the sum of squared within-cluster distances (SSW) for a given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame containing the data.\n",
    "    feats (list of str): A list of feature column names to be used in the calculation.\n",
    "    label_col (str): The name of the column containing cluster labels.\n",
    "\n",
    "    Returns:\n",
    "    float: The sum of squared within-cluster distances (SSW).\n",
    "    \"\"\"\n",
    "    feats_label = feats+[label_col]\n",
    "\n",
    "    df_k = df[feats_label].groupby(by=label_col).apply(lambda col: get_ss(col, feats), \n",
    "                                                       include_groups=False)\n",
    "\n",
    "    return df_k.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSb:   40535.715982027425\n",
      "SSw:   47634.284017972604\n",
      "SSt:   88170.00000000032\n",
      "SSt == SSb+SSw ?  False\n"
     ]
    }
   ],
   "source": [
    "df_sst_ = get_ss(df_concat, metric_features)\n",
    "df_ssb_ = get_ssb(df_concat, metric_features, 'labels')\n",
    "df_ssw_ = get_ssw(df_concat, metric_features, 'labels')\n",
    "\n",
    "print(\"SSb:  \", df_ssb_)\n",
    "print(\"SSw:  \", df_ssw_)\n",
    "print(\"SSt:  \", df_sst_)\n",
    "print(\"SSt == SSb+SSw ? \", (df_sst_ == df_ssb_ + df_ssw_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $R^2$\n",
    "\n",
    "The $R^2$ is a measure of the homogeneity of a cluster solution. \n",
    "\n",
    "It is based on: \n",
    "\n",
    "\n",
    "$$\n",
    "SS_t = SS_w + SS_b\n",
    "\\\\\n",
    "\\\\\n",
    "R^2 = \\cfrac{SS_b}{SS_t}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/clustering/ss_k1_kn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/clustering/r2_k1_kn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find the best linkage method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def get_rsq(df, feats, label_col):\n",
    "    \"\"\"\n",
    "    Calculate the R-squared value for a given DataFrame and features.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing the data.\n",
    "    feats (list): A list of feature column names to be used in the calculation.\n",
    "    label_col (str): The name of the column containing the labels or cluster assignments.\n",
    "\n",
    "    Returns:\n",
    "    float: The R-squared value, representing the proportion of variance explained by the clustering.\n",
    "    \"\"\"\n",
    "\n",
    "    df_sst_ = get_ss(df, feats)                 # get total sum of squares\n",
    "    df_ssw_ = get_ssw(df, feats, label_col)     # get ss within\n",
    "    df_ssb_ = df_sst_ - df_ssw_                 # get ss between\n",
    "\n",
    "    # r2 = ssb/sst \n",
    "    return (df_ssb_/df_sst_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#### Complete the code in the function\n",
    "####################################\n",
    "\n",
    "def get_r2_hc(df, link_method, max_nclus, min_nclus=1, dist=\"euclidean\"):\n",
    "    \"\"\"This function computes the R2 for a set of cluster solutions given by the application of a hierarchical method.\n",
    "    The R2 is a measure of the homogenity of a cluster solution. It is based on SSt = SSw + SSb and R2 = SSb/SSt. \n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Dataset to apply clustering\n",
    "    link_method (str): either \"ward\", \"complete\", \"average\", \"single\"\n",
    "    max_nclus (int): maximum number of clusters to compare the methods\n",
    "    min_nclus (int): minimum number of clusters to compare the methods. Defaults to 1.\n",
    "    dist (str): distance to use to compute the clustering solution. Must be a valid distance. Defaults to \"euclidean\".\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: R2 values for the range of cluster solutions\n",
    "    \"\"\"\n",
    "    \n",
    "    r2 = []  # where we will store the R2 metrics for each cluster solution\n",
    "    feats = df.columns.tolist()\n",
    "    \n",
    "    for i in range(min_nclus, max_nclus+1):  # iterate over desired ncluster range\n",
    "        \n",
    "        # CODE HERE ####################################\n",
    "        cluster = AgglomerativeClustering(linkage=link_method,\n",
    "                                          \n",
    "                                         n_clusters=1)\n",
    "        \n",
    "        #get cluster labels\n",
    "        # CODE HERE ####################################\n",
    "        hclabels = None   \n",
    "        \n",
    "        # concat df with labels\n",
    "        df_concat = pd.concat([df, pd.Series(hclabels, name='labels', index=df.index)], axis=1)  \n",
    "        \n",
    "        \n",
    "        # append the R2 of the given cluster solution\n",
    "        r2.append(get_rsq(df_concat, feats, 'labels'))\n",
    "        \n",
    "    return np.array(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# THIS TAKES A FEW MINUTES TO RUN!!\n",
    "##########################################\n",
    "\n",
    "hc_methods = [\"ward\", \"complete\", \"average\", \"single\"]\n",
    "max_nclus = 10\n",
    "\n",
    "r2_hc = np.vstack([ get_r2_hc(df[metric_features], \n",
    "                              link, \n",
    "                              max_nclus=max_nclus, \n",
    "                              min_nclus=1, \n",
    "                              dist=\"euclidean\") \n",
    "                              for link in hc_methods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (10, 40), indices imply (10, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r2_hc_methods \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(r2_hc\u001b[38;5;241m.\u001b[39mT, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_nclus \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), columns\u001b[38;5;241m=\u001b[39mhc_methods)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[1;32m    825\u001b[0m         )\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    828\u001b[0m             data,\n\u001b[1;32m    829\u001b[0m             index,\n\u001b[1;32m    830\u001b[0m             columns,\n\u001b[1;32m    831\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    832\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    833\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    834\u001b[0m         )\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (10, 40), indices imply (10, 4)"
     ]
    }
   ],
   "source": [
    "r2_hc_methods = pd.DataFrame(r2_hc.T, index=range(1, max_nclus + 1), columns=hc_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "# Plot data\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "sns.lineplot(data=r2_hc_methods, linewidth=2.5, markers=[\"o\"]*4)\n",
    "\n",
    "# Finalize the plot\n",
    "plt.legend(title=\"HC methods\", title_fontsize=11)\n",
    "plt.xticks(range(1, max_nclus + 1))\n",
    "plt.xlabel(\"Number of clusters\", fontsize=13)\n",
    "plt.ylabel(\"R2 metric\", fontsize=13)\n",
    "\n",
    "fig.suptitle(\"$R^2$ plot for various hierarchical methods\", fontsize=21)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the number of clusters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the **first big jump** on the Dendrogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting distance_threshold=0 and n_clusters=None ensures we compute the full tree\n",
    "linkage = \"ward\" # CODE HERE\n",
    "distance = \"euclidean\" # CODE HERE\n",
    "\n",
    "\n",
    "hclust = AgglomerativeClustering(linkage=linkage,\n",
    "                                metric=distance) # CODE HERE\n",
    "hclust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py\n",
    "\n",
    "# create the counts of samples under each node (number of points being merged)\n",
    "counts = np.zeros(hclust.children_.shape[0])\n",
    "n_samples = len(hclust.labels_)\n",
    "\n",
    "# hclust.children_ contains the observation ids that are being merged together\n",
    "# At the i-th iteration, children[i][0] and children[i][1] are merged to form node n_samples + i\n",
    "for i, merge in enumerate(hclust.children_):\n",
    "    # track the number of observations in the current cluster being formed\n",
    "    current_count = 0\n",
    "    for child_idx in merge:\n",
    "        if child_idx < n_samples:\n",
    "            # If this is True, then we are merging an observation\n",
    "            current_count += 1  # leaf node\n",
    "        else:\n",
    "            # Otherwise, we are merging a previously formed cluster\n",
    "            current_count += counts[child_idx - n_samples]\n",
    "    counts[i] = current_count\n",
    "\n",
    "# the hclust.children_ is used to indicate the two points/clusters being merged (dendrogram's u-joins)\n",
    "# the hclust.distances_ indicates the distance between the two points/clusters (height of the u-joins)\n",
    "# the counts indicate the number of points being merged (dendrogram's x-axis)\n",
    "linkage_matrix = np.column_stack(\n",
    "    [hclust.children_, hclust.distances_, counts]\n",
    ").astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corresponding dendrogram\n",
    "sns.set()\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "# The Dendrogram parameters need to be tuned\n",
    "y_threshold = 100\n",
    "dendrogram(linkage_matrix, truncate_mode='level', p=5, color_threshold=y_threshold, above_threshold_color='k')\n",
    "plt.hlines(y_threshold, 0, 1000, colors=\"r\", linestyles=\"dashed\")\n",
    "plt.title(f'Hierarchical Clustering Dendrogram: {linkage.title()} Linkage', fontsize=21)\n",
    "plt.xlabel('Number of points in node (or index of point if no parenthesis)')\n",
    "plt.ylabel(f'{distance.title()} Distance', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Visualize the Dendrogram with y_threshold = 75\n",
    "##########################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cluster solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage = 'ward'\n",
    "distance = 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 cluster solution\n",
    "n_clusters = None\n",
    "\n",
    "hc4_clust = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "hc4_labels = hc4_clust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the 4 clusters\n",
    "df_concat = pd.concat([df[metric_features], \n",
    "                       pd.Series(hc4_labels, \n",
    "                                 name='labels', \n",
    "                                 index=df.index)], \n",
    "                    axis=1)\n",
    "\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 cluster solution\n",
    "\n",
    "hc5_clust = AgglomerativeClustering()\n",
    "hc5_labels = hc5_clust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the 5 clusters\n",
    "df_concat = pd.concat([df[metric_features], \n",
    "                       pd.Series(hc5_labels, \n",
    "                                 name='labels', \n",
    "                                 index=df.index)], \n",
    "                    axis=1)\n",
    "\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## See crosstab of 4 vs 5\n",
    "## What does this mean?\n",
    "\n",
    "pd.crosstab(\n",
    "    pd.Series(hc5_labels, name='hc5_labels', index=df.index),\n",
    "    pd.Series(hc4_labels, name='hc4_labels', index=df.index),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Hierarchical clustering solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cluster solution\n",
    "linkage = None # CODE HERE\n",
    "distance = None # CODE HERE\n",
    "n_clusters = None # CODE HERE\n",
    "hclust = AgglomerativeClustering()\n",
    "\n",
    "hc_labels = hclust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the final clusters\n",
    "\n",
    "df_concat = pd.concat([\n",
    "    df[metric_features], \n",
    "    pd.Series(hc_labels, name='labels', index=df.index)\n",
    "    ], \n",
    "    axis=1)\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Visualize the cluster means as a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "hc_profile = df_concat.groupby('labels').mean().T\n",
    "\n",
    "sns.heatmap(hc_profile,\n",
    "            ax=ax \n",
    "            ) # How can we improve this?\n",
    "\n",
    "ax.set_xlabel(\"Cluster Labels\")\n",
    "ax.set_title(\"Cluster Profiling:\\nHierarchical Clustering with 4 Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Compare the cluster means to the population means. \n",
    "\n",
    "Visualize the cluster means with the population means in the same heatmap.\n",
    "\n",
    "Explain these values for the population means.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Visualize the cluster means with the cluster sizes\n",
    "\n",
    "Create a subplot with 1 row and 2 columns.\n",
    "\n",
    "In the left subplot, visualize the heatmap of cluster means, and in the right subplot visualize the cluster sizes.\n",
    "\n",
    "*Hint:* Use `sns.countplot()`.\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.countplot.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = None \n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,5), width_ratios=[.6,.4], tight_layout=True)\n",
    "\n",
    "# sns.heatmap(..., ax=axes[0])\n",
    "\n",
    "axes[0].set_xlabel(\"Cluster Labels\")\n",
    "axes[0].set_title(\"Heatmap of Cluster Means\")\n",
    "\n",
    "\n",
    "# sns.countplot(..., ax=axes[1])\n",
    "axes[1].set_title(\"Cluster Sizes\")\n",
    "axes[1].set_xlabel(\"Cluster Labels\")\n",
    "\n",
    "fig.suptitle(\"Cluster Profiling:\\nHierarchical Clustering with 4 Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "The figure below shows the dendrogram produced by using the single linkage method to cluster the datapoints given. Identify the letter in the dendrogram corresponding to each point in the scatter plot:\n",
    "\n",
    "*Example:* Point 10 = Letter L\n",
    "\n",
    "![HC Exercise](./../figures/clustering/hc_exer_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More references on cluster evaluation:\n",
    "\n",
    "\n",
    "Halkidi, M., Batistakis, Y., & Vazirgiannis, M. (2002). Clustering validity checking methods. *ACM SIGMOD Record*, 31(3), 19â€“27. https://doi.org/10.1145/601858.601862\n",
    "\n",
    "Liu, Y., Li, Z., Xiong, H., Gao, X. & Wu, J. (2010), Understanding of Internal Clustering Validation Measures, *2010 IEEE International Conference on Data Mining*, Sydney, NSW, Australia, 2010, pp. 911-916, https://10.1109/ICDM.2010.35. \n",
    "\n",
    "\n",
    "Pandove, D., Goel, S., & Rani, R. (2018). Systematic Review of Clustering High-Dimensional and Large Datasets. *ACM Transactions on Knowledge Discovery From Data*, 12(2), 1â€“68. https://doi.org/10.1145/3132088\n",
    "\n",
    "\n",
    "Todeschini, R., Ballabio, D., Termopoli, V., & Consonni, V. (2024). Extended multivariate comparison of 68 cluster validity indices. A review. *Chemometrics and Intelligent Laboratory Systems*, 251, 105117. https://doi.org/10.1016/j.chemolab.2024.105117\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Session: K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
